
<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>Introduction to MPI &#8212; A Python Introduction to Parallel Programming with MPI 1 documentation</title>
    <link rel="stylesheet" href="static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="static/pygments.css" type="text/css" />
    <script type="text/javascript" id="documentation_options" data-url_root="./" src="static/documentation_options.js"></script>
    <script type="text/javascript" src="static/jquery.js"></script>
    <script type="text/javascript" src="static/underscore.js"></script>
    <script type="text/javascript" src="static/doctools.js"></script>
    <script type="text/javascript" src="static/language_data.js"></script>
    <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Point-to-Point Communication" href="pointToPoint.html" />
    <link rel="prev" title="An Overview of Parallel Computing" href="overview.html" />
   
  <link rel="stylesheet" href="static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <div class="section" id="introduction-to-mpi">
<span id="intrompi"></span><h1>Introduction to MPI<a class="headerlink" href="#introduction-to-mpi" title="Permalink to this headline">¶</a></h1>
<div class="section" id="hello-world">
<h2>Hello World<a class="headerlink" href="#hello-world" title="Permalink to this headline">¶</a></h2>
<p>As tradition has it, we will introduce you to MPI programming using a variation on the standard hello world program: your first MPI python program will be the Hello World program for multiple processes. The source code is as follows:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#hello.py</span>
<span class="kn">from</span> <span class="nn">mpi4py</span> <span class="k">import</span> <span class="n">MPI</span>
<span class="n">comm</span> <span class="o">=</span> <span class="n">MPI</span><span class="o">.</span><span class="n">COMM_WORLD</span>
<span class="n">rank</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">Get_rank</span><span class="p">()</span>
<span class="nb">print</span> <span class="s2">&quot;hello world from process &quot;</span><span class="p">,</span> <span class="n">rank</span>
</pre></div>
</div>
<p>After saving this text as <em>hello.py</em>, it is executed using the following command-line syntax, run from the file’s directory:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ mpiexec  -n 5 python  hello.py
</pre></div>
</div>
<p>The above command will execute five python processes which can all communicate with each other. When each program runs, it will print hello, and tell you its rank:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">hello</span> <span class="n">world</span> <span class="kn">from</span> <span class="nn">process</span> <span class="mi">0</span>
<span class="n">hello</span> <span class="n">world</span> <span class="kn">from</span> <span class="nn">process</span> <span class="mi">1</span>
<span class="n">hello</span> <span class="n">world</span> <span class="kn">from</span> <span class="nn">process</span> <span class="mi">3</span>
<span class="n">hello</span> <span class="n">world</span> <span class="kn">from</span> <span class="nn">process</span> <span class="mi">2</span>
<span class="n">hello</span> <span class="n">world</span> <span class="kn">from</span> <span class="nn">process</span> <span class="mi">4</span>
</pre></div>
</div>
<p>Notice that when you try this on your own, they do not necessarily print in order. This is because 5 separate processes are running on different processors, and we cannot know beforehand which one will execute its print statement first. If the processes are being scheduled on the same processor instead of multiple processors, then it is up to the operating system to schedule the processes, and it has no preference of any one of our processes over any other process of ours. In essence, each process executes autonomously.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>It is usually bad practice to perform I/O (e.g., call <code class="docutils literal notranslate"><span class="pre">print</span></code>) from any process besides the root process, though it can oftentimes be a useful tool for debugging (for more information see the chapter <a class="reference internal" href="IOandDebugging.html#ioanddebugging"><span class="std std-ref">I/O, Debugging, and Performance</span></a>). We do it here, however, for pedagogical purposes.</p>
</div>
</div>
<div class="section" id="execution">
<h2>Execution<a class="headerlink" href="#execution" title="Permalink to this headline">¶</a></h2>
<p>As mentioned in the section An Overview of Parallel Computing, <em>mpi4py</em> programs are single-program multiple-data programs, and therefore each process will run the same code a bit differently. When we execute the command below, a number of things happen.:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ mpiexec  -n 5 python  hello.py
</pre></div>
</div>
<p>First, the mpiexec program is launched. This is the program which starts MPI, a wrapper around whatever program you to pass into it. The <code class="docutils literal notranslate"><span class="pre">-n</span> <span class="pre">5</span></code> option specifies the desired number of processes. In our case, 5 processes are run, each one being an instance of python. To each of the 5 instances of python, we pass the argument <code class="docutils literal notranslate"><span class="pre">hello.py</span></code> which is the name of our program’s text file, located in the current directory. Each of the five instances of python then opens the <em>.py</em> file and runs the same program. The difference in each process’s execution environment is that the processes are given different ranks in the communicator. Because of this, each process prints a different number when it executes.</p>
<p>MPI and python combine to make wonderfully succinct source code. The second line of the above program (the first line is a comment) makes available the MPI module from the mpi4py package. Using the <code class="docutils literal notranslate"><span class="pre">.</span></code> operator we can access a static communicator object, of which the current process can learn about its rank.</p>
<p>This program introduces us to the root <em>mpi4py</em> class, <em>Comm</em>, which stands for Communicator. <code class="docutils literal notranslate"><span class="pre">MPI.COMM_WORLD</span></code> is a static reference to a <em>Comm</em> object, and <code class="docutils literal notranslate"><span class="pre">comm</span></code> is just a reference to it for our convenience. We could have omitted line three, and simply used <code class="docutils literal notranslate"><span class="pre">MPI.COMM_WORLD</span></code> in place of <code class="docutils literal notranslate"><span class="pre">comm</span></code> and the program would have behaved identically. A “communicator” represents a system of computers or processors which can communicate with each other via MPI commands. <em>Comm</em> objects have many methods and properties, shown in the appendix, <a class="reference internal" href="appendix.html#commmethods"><span class="std std-ref">Instance Methods of Comm Class</span></a>. Read over this section to get a high-level understanding of the bulk of MPI. Not all of the methods in the Comm object correlate to the MPI specification, but most of them do.</p>
</div>
<div class="section" id="the-communicator">
<h2>The Communicator<a class="headerlink" href="#the-communicator" title="Permalink to this headline">¶</a></h2>
<p>A communicator is a logical unit that defines which processes are allowed to send and receive messages. By organizing processes this way, MPI can physically rearrange which processes are assigned to which CPUs, and optimize your program for speed.</p>
<div class="section" id="intracommunicators-and-intercommunicators">
<h3>Intracommunicators and Intercommunicators<a class="headerlink" href="#intracommunicators-and-intercommunicators" title="Permalink to this headline">¶</a></h3>
<p>Intracommunicators are the most commonly used form of communicator in MPI. Each intracommunicator contains a set of processes, each of which is identified by its “rank” within the communicator. The ranks are numbered 0 through <code class="docutils literal notranslate"><span class="pre">Size-1</span></code>. Any process in the communicator can send a message to another process within the communicator or receive a message from any other process in the communicator. Intracommunicators also support a variety of collective operations that involve all of the processes in the communicator. Most MPI communication occurs within intracommunicators. Intercommunicators provide a sophisticated method of implementing complex communications, but very few MPI programs require them.</p>
<p>The hierarchy of communicators is shown in the figure below <a class="reference internal" href="#commhier"><span class="std std-ref">The Hierarchy of Communicators</span></a>. In this document we will focus on intracommunicator communication.</p>
<div class="figure align-center" id="id1">
<span id="commhier"></span><img alt="_images/commHier.png" src="_images/commHier.png" />
<p class="caption"><span class="caption-text">The Hierarchy of Communicators</span><a class="headerlink" href="#id1" title="Permalink to this image">¶</a></p>
</div>
</div>
</div>
<div class="section" id="finding-out-about-the-rest-of-the-world">
<h2>Finding Out About the Rest of the World<a class="headerlink" href="#finding-out-about-the-rest-of-the-world" title="Permalink to this headline">¶</a></h2>
<p>In <em>mpi4py</em>, ranks are essential to learning about other processes. A rank is the process’s id within a communicator. A process can be part of more than one communicator at any given time. When <code class="docutils literal notranslate"><span class="pre">Comm.Get_rank()</span></code> is called in your program, it gets called by every process in the communicator variable <code class="docutils literal notranslate"><span class="pre">comm</span></code>, and the rank of each respective process is stored into the variable pointed to by rank. Remember, rank points to a local variable, which is unique for every calling process because each process has its own separate copy of local variables.</p>
<p><code class="docutils literal notranslate"><span class="pre">Get_Rank</span></code>, when used with <code class="docutils literal notranslate"><span class="pre">Get_Size</span></code>, forms the central method for finding out about other processes. <code class="docutils literal notranslate"><span class="pre">Comm.Get_Size</span></code> returns the number of processors in the communicator. Using these two subroutines, a process can learn where it stands in its communicator and who else is out there. All it needs to know to communicate with another process is that other process’s rank, which ranges from 0 to <code class="docutils literal notranslate"><span class="pre">comm.size</span> <span class="pre">-</span> <span class="pre">1</span></code> excluding the process’s own rank.</p>
</div>
<div class="section" id="get-size-and-get-rank">
<h2>Get_size() and Get_rank()<a class="headerlink" href="#get-size-and-get-rank" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="Comm.Get_size">
<code class="descclassname">Comm.</code><code class="descname">Get_size</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#Comm.Get_size" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the number of processes in the communicator. It will return the same number to every process.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>Comm</strong> (<em>MPI comm</em>) – communicator we wish to query</p>
</dd>
<dt class="field-even">Rvalue</dt>
<dd class="field-even"><p>number of processes in the communicator</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>integer</p>
</dd>
</dl>
</dd></dl>

<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mpi4py</span> <span class="k">import</span> <span class="n">MPI</span>
<span class="n">size</span> <span class="o">=</span> <span class="n">MPI</span><span class="o">.</span><span class="n">COMM_WORLD</span><span class="o">.</span><span class="n">Get_size</span><span class="p">()</span>
</pre></div>
</div>
<dl class="function">
<dt id="Comm.Get_rank">
<code class="descclassname">Comm.</code><code class="descname">Get_rank</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#Comm.Get_rank" title="Permalink to this definition">¶</a></dt>
<dd><p>Determines the rank of the calling process in the communicator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>Comm</strong> (<em>MPI comm</em>) – communicator we wish to query</p>
</dd>
<dt class="field-even">Rvalue</dt>
<dd class="field-even"><p>rank of the calling process in the communicator</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>integer</p>
</dd>
</dl>
</dd></dl>

<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mpi4py</span> <span class="k">import</span> <span class="n">MPI</span>
<span class="n">rank</span> <span class="o">=</span> <span class="n">MPI</span><span class="o">.</span><span class="n">COMM_WORLD</span><span class="o">.</span><span class="n">Get_rank</span><span class="p">()</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Note that one of the main differences between this presentation of mpi4py and MPI in C or Fortan, besides being array-based, is that mpi4py is largely object oriented. The MPI Communicator in mpi4py is a Python class and MPI functions like <em>Get_size()</em> or <em>Get_rank()</em> are instance methods of the communicator class. Throughout the tutorial you will see functions like <code class="docutils literal notranslate"><span class="pre">Get_rank()</span></code> are presented as <code class="docutils literal notranslate"><span class="pre">Comm.Get_rank()</span></code> where it is implied that <code class="docutils literal notranslate"><span class="pre">Comm</span></code> is an instance of the <em>Comm</em> class. I will document <code class="docutils literal notranslate"><span class="pre">Comm</span></code> as in input parameter to the function.</p>
</div>
</div>
<div class="section" id="seperate-codes-in-one-file">
<h2>Seperate Codes in One File<a class="headerlink" href="#seperate-codes-in-one-file" title="Permalink to this headline">¶</a></h2>
<p>When an MPI program is run, each process receives the same code. However, each process is assigned a different rank. This allows us to embed a seperate code for each process into one file. In the following code, all processes are given the same two numbers. However, though there is only one file, 3 processes are given completely different instructions for what to do with them. Process 0 sums them, process 1 multiplies them, and process 2 takes the maximum of them:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#seperateCodes.py</span>
<span class="kn">from</span> <span class="nn">mpi4py</span> <span class="k">import</span> <span class="n">MPI</span>
<span class="n">rank</span> <span class="o">=</span> <span class="n">MPI</span><span class="o">.</span><span class="n">COMM_WORLD</span><span class="o">.</span><span class="n">Get_rank</span><span class="p">()</span>

<span class="n">a</span> <span class="o">=</span> <span class="mf">6.0</span>
<span class="n">b</span> <span class="o">=</span> <span class="mf">3.0</span>
<span class="k">if</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nb">print</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span>
<span class="k">if</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="nb">print</span> <span class="n">a</span> <span class="o">*</span> <span class="n">b</span>
<span class="k">if</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
        <span class="nb">print</span> <span class="nb">max</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="exercises">
<h2>Exercises<a class="headerlink" href="#exercises" title="Permalink to this headline">¶</a></h2>
<ol class="arabic simple">
<li><p>Write the “Hello World” program from above so that every process prints out its rank and the size of the communicator (for example, process 3 on a communicator of size 5 prints “Hello World from process 3 out of 5!”).</p></li>
<li><p>Write a program in which the the processes with even rank print “Hello” and process with odd rank print “Goodbye.” Print the process number along with the “Hello” or “Goodbye” (for example, “Goodbye from process 3”).</p></li>
<li><p>Sometimes the program you write can only run correctly if it has a certain number of processes. Although you typically want to avoid writing these kinds of programs, sometimes it is inconvenient or unavoidable. Write a program that runs only if it has 5 processes. Upon failure, the root node should print “Error: This program must run with 5 processes” and upon success it should print “Success!” To exit, call the function <code class="docutils literal notranslate"><span class="pre">Comm.Abort()</span></code>.</p></li>
</ol>
</div>
</div>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="index.html">A Python Introduction to Parallel Programming with MPI</a></h1>








<h3>Navigation</h3>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="preface.html">Preface</a></li>
<li class="toctree-l1"><a class="reference internal" href="overview.html">An Overview of Parallel Computing</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Introduction to MPI</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#hello-world">Hello World</a></li>
<li class="toctree-l2"><a class="reference internal" href="#execution">Execution</a></li>
<li class="toctree-l2"><a class="reference internal" href="#the-communicator">The Communicator</a></li>
<li class="toctree-l2"><a class="reference internal" href="#finding-out-about-the-rest-of-the-world">Finding Out About the Rest of the World</a></li>
<li class="toctree-l2"><a class="reference internal" href="#get-size-and-get-rank">Get_size() and Get_rank()</a></li>
<li class="toctree-l2"><a class="reference internal" href="#seperate-codes-in-one-file">Seperate Codes in One File</a></li>
<li class="toctree-l2"><a class="reference internal" href="#exercises">Exercises</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="pointToPoint.html">Point-to-Point Communication</a></li>
<li class="toctree-l1"><a class="reference internal" href="collectiveCom.html">Collective Communication</a></li>
<li class="toctree-l1"><a class="reference internal" href="IOandDebugging.html">I/O, Debugging, and Performance</a></li>
<li class="toctree-l1"><a class="reference internal" href="appendix.html">Appendix</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
      <li>Previous: <a href="overview.html" title="previous chapter">An Overview of Parallel Computing</a></li>
      <li>Next: <a href="pointToPoint.html" title="next chapter">Point-to-Point Communication</a></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2019, Jeremy Bejarano.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 2.0.1</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="_sources/introMPI.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>