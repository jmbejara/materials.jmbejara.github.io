
<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>Appendix &#8212; A Python Introduction to Parallel Programming with MPI 1.0.2 documentation</title>
    <link rel="stylesheet" href="_static/classic.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="_static/language_data.js"></script>
    <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="I/O, Debugging, and Performance" href="IOandDebugging.html" /> 
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="IOandDebugging.html" title="I/O, Debugging, and Performance"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">A Python Introduction to Parallel Programming with MPI 1.0.2 documentation</a> &#187;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="appendix">
<span id="id1"></span><h1>Appendix<a class="headerlink" href="#appendix" title="Permalink to this headline">¶</a></h1>
<p>Here is an abbreviated reference of the features of mpi4py. For a full documentation of the API, see <a class="reference external" href="http://mpi4py.scipy.org/docs/apiref/">http://mpi4py.scipy.org/docs/apiref/</a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>One of the main differences between this presentation of mpi4py and MPI in C or Fortan, besides being array-based, is that mpi4py is largely object oriented. The MPI Communicator in mpi4py is a Python class and MPI functions like <em>Send</em> or <em>Broadcast</em> are instance methods of the communicator class. The object-oriented nature of mpi4py is seen mostly in dealing with MPI topologies. I will not discuss these in detail, but rather focus on an introduction to the basics of distributed memory programming with MPI. Throughout the tutorial you will see functions like <code class="docutils literal notranslate"><span class="pre">Send(...)</span></code> presented as <code class="docutils literal notranslate"><span class="pre">Comm.Send(...)</span></code> where it is implied that <code class="docutils literal notranslate"><span class="pre">Comm</span></code> is an instance of the <em>Comm</em> class. I will document <code class="docutils literal notranslate"><span class="pre">Comm</span></code> as in input paramter to the function.</p>
</div>
<div class="section" id="instance-methods-of-comm-class">
<span id="commmethods"></span><h2>Instance Methods of <em>Comm</em> Class<a class="headerlink" href="#instance-methods-of-comm-class" title="Permalink to this headline">¶</a></h2>
<p>For full documentation of the <em>Comm</em> class, see <a class="reference external" href="http://mpi4py.scipy.org/docs/apiref/mpi4py.MPI.Comm-class.html">http://mpi4py.scipy.org/docs/apiref/mpi4py.MPI.Comm-class.html</a>.</p>
<div class="section" id="uppercase-communication">
<h3>“Uppercase” Communication<a class="headerlink" href="#uppercase-communication" title="Permalink to this headline">¶</a></h3>
<dl class="glossary simple">
<dt id="term-abort-errorcode-0">Abort( errorcode=0)</dt><dd><p>Terminate MPI execution environment</p>
</dd>
<dt id="term-allgather-sendbuf-recvbuf">Allgather(sendbuf, recvbuf)</dt><dd><p>Gather to All, gather data from all processes and distribute it to all other processes in a group</p>
</dd>
<dt id="term-allgatherv-sendbuf-recvbuf">Allgatherv(sendbuf, recvbuf)</dt><dd><p>Gather to All Vector, gather data from all processes and distribute it to all other processes in a group providing different amount of data and displacements</p>
</dd>
<dt id="term-allreduce-sendbuf-recvbuf-op-op-sum">Allreduce(sendbuf, recvbuf, Op op=SUM)</dt><dd><p>All Reduce</p>
</dd>
<dt id="term-alltoall-sendbuf-recvbuf">Alltoall(sendbuf, recvbuf)</dt><dd><p>All to All Scatter/Gather, send data from all to all processes in a group</p>
</dd>
<dt id="term-alltoallv-sendbuf-recvbuf">Alltoallv(sendbuf, recvbuf)</dt><dd><p>All to All Scatter/Gather Vector, send data from all to all processes in a group providing different amount of data and displacements</p>
</dd>
<dt id="term-alltoallw-sendbuf-recvbuf">Alltoallw(sendbuf, recvbuf)</dt><dd><p>Generalized All-to-All communication allowing different counts, displacements and datatypes for each partner</p>
</dd>
<dt id="term-barrier">Barrier()</dt><dd><p>Barrier synchronization</p>
</dd>
<dt id="term-bcast-buf-root-0">Bcast(buf, root=0)</dt><dd><p>Broadcast a message from one process to all other processes in a group</p>
</dd>
<dt id="term-bsend-buf-dest-0-tag-0">Bsend(buf, dest=0, tag=0)</dt><dd><p>Blocking send in buffered mode</p>
</dd>
<dt id="term-bsend-init-buf-dest-0-tag-0">Bsend_init(buf, dest=0, tag=0)</dt><dd><p>Persistent request for a send in buffered mode</p>
</dd>
<dt id="term-call-errhandler-errorcode">Call_errhandler(errorcode)</dt><dd><p>Call the error handler installed on a communicator</p>
</dd>
<dt id="term-clone">Clone()</dt><dd><p>Clone an existing communicator</p>
</dd>
<dt id="term-compare-type-cls-comm-comm1-comm-comm2">Compare(type cls, Comm comm1, Comm comm2)</dt><dd><p>Compare two communicators</p>
</dd>
<dt id="term-disconnect">Disconnect()</dt><dd><p>Disconnect from a communicator</p>
</dd>
<dt id="term-free">Free()</dt><dd><p>Free a communicator</p>
</dd>
<dt id="term-gather-sendbuf-recvbuf-root-0">Gather(sendbuf, recvbuf, root=0)</dt><dd><p>Gather together values from a group of processes</p>
</dd>
<dt id="term-gatherv-sendbuf-recvbuf-root-0">Gatherv(sendbuf, recvbuf, root=0)</dt><dd><p>Gather Vector, gather data to one process from all other processes in a group providing different amount of data and displacements at the receiving sides</p>
</dd>
<dt id="term-get-attr-keyval">Get_attr(keyval)</dt><dd><p>Retrieve attribute value by key</p>
</dd>
<dt id="term-get-errhandler">Get_errhandler()</dt><dd><p>Get the error handler for a communicator</p>
</dd>
<dt id="term-get-group">Get_group()</dt><dd><p>Access the group associated with a communicator</p>
</dd>
<dt id="term-get-name">Get_name()</dt><dd><p>Get the print name for this communicator</p>
</dd>
<dt id="term-get-parent-type-cls">Get_parent(type cls)</dt><dd><p>Return the parent intercommunicator for this process</p>
</dd>
<dt id="term-get-rank">Get_rank()</dt><dd><p>Return the rank of this process in a communicator</p>
</dd>
<dt id="term-get-size">Get_size()</dt><dd><p>Return the number of processes in a communicator</p>
</dd>
<dt id="term-get-topology">Get_topology()</dt><dd><p>Determine the type of topology (if any) associated with a communicator</p>
</dd>
<dt id="term-ibsend-buf-dest-0-tag-0">Ibsend(buf, dest=0, tag=0)</dt><dd><p>Nonblocking send in buffered mode</p>
</dd>
<dt id="term-iprobe-source-0-tag-0-status-status-none">Iprobe(source=0, tag=0, Status status=None)</dt><dd><p>Nonblocking test for a message</p>
</dd>
<dt id="term-irecv-buf-source-0-tag-0">Irecv(buf, source=0, tag=0)</dt><dd><p>Nonblocking receive</p>
</dd>
<dt id="term-irsend-buf-dest-0-tag-0">Irsend(buf, dest=0, tag=0)</dt><dd><p>Nonblocking send in ready mode</p>
</dd>
<dt id="term-is-inter">Is_inter()</dt><dd><p>Test to see if a comm is an intercommunicator</p>
</dd>
<dt id="term-is-intra">Is_intra()</dt><dd><p>Test to see if a comm is an intracommunicator</p>
</dd>
<dt id="term-isend-buf-dest-0-tag-0">Isend(buf, dest=0, tag=0)</dt><dd><p>Nonblocking send</p>
</dd>
<dt id="term-issend-buf-dest-0-tag-0">Issend(buf, dest=0, tag=0)</dt><dd><p>Nonblocking send in synchronous mode</p>
</dd>
<dt id="term-join-type-cls-fd">Join(type cls, fd)</dt><dd><p>Create a intercommunicator by joining two processes connected by a socket</p>
</dd>
<dt id="term-probe-source-0-tag-0-status-status-none">Probe(source=0, tag=0, Status status=None)</dt><dd><p>Blocking test for a message</p>
</dd>
<dt id="term-recv-buf-source-0-tag-0-status-status-none">Recv(buf, source=0, tag=0, Status status=None)</dt><dd><p>Blocking receive</p>
</dd>
<dt id="term-recv-init-buf-source-0-tag-0">Recv_init(buf, source=0, tag=0)</dt><dd><p>Create a persistent request for a receive</p>
</dd>
<dt id="term-reduce-sendbuf-recvbuf-op-op-sum-root-0">Reduce(sendbuf, recvbuf, Op op=SUM, root=0)</dt><dd><p>Reduce</p>
</dd>
<dt id="term-reduce-scatter-sendbuf-recvbuf-recvcounts-none-op-op-sum">Reduce_scatter(sendbuf, recvbuf, recvcounts=None, Op op=SUM)</dt><dd><p>Reduce-Scatter (vector version)</p>
</dd>
<dt id="term-reduce-scatter-block-sendbuf-recvbuf-op-op-sum">Reduce_scatter_block(sendbuf, recvbuf, Op op=SUM)</dt><dd><p>Reduce-Scatter Block (regular, non-vector version)</p>
</dd>
<dt id="term-rsend-buf-dest-0-tag-0">Rsend(buf, dest=0, tag=0)</dt><dd><p>Blocking send in ready mode</p>
</dd>
<dt id="term-rsend-init-buf-dest-0-tag-0">Rsend_init(buf, dest=0, tag=0)</dt><dd><p>Persistent request for a send in ready mode</p>
</dd>
<dt id="term-scatter-sendbuf-recvbuf-root-0">Scatter(sendbuf, recvbuf, root=0)</dt><dd><p>Scatter Vector, scatter data from one process to all other processes in a group</p>
</dd>
<dt id="term-scatterv-choice-sendbuf-tuple-int-sendcounts-tuple-int-displacements-mpi-datatype-sendtype-choice-recvbuf-root-0">Scatterv([choice sendbuf, tuple_int sendcounts, tuple_int displacements, MPI_Datatype sendtype], choice recvbuf, root=0)</dt><dd><p>Scatter data from one process to all other processes in a group providing different amount of data and displacements at the sending side</p>
</dd>
<dt id="term-send-buf-dest-0-tag-0">Send(buf, dest=0, tag=0)</dt><dd><p>Blocking send</p>
</dd>
<dt id="term-send-init-buf-dest-0-tag-0">Send_init(buf, dest=0, tag=0)</dt><dd><p>Create a persistent request for a standard send</p>
</dd>
<dt id="term-sendrecv-sendbuf-dest-0-sendtag-0-recvbuf-none-source-0-recvtag-0-status-status-none">Sendrecv(sendbuf, dest=0, sendtag=0, recvbuf=None, source=0, recvtag=0, Status status=None)</dt><dd><p>Send and receive a message</p>
</dd>
<dt id="term-sendrecv-replace-buf-dest-0-sendtag-0-source-0-recvtag-0-status-status-none">Sendrecv_replace(buf, dest=0, sendtag=0, source=0, recvtag=0, Status status=None)</dt><dd><p>Send and receive a message</p>
</dd>
<dt id="term-set-errhandler-errhandler-errhandler">Set_errhandler(Errhandler errhandler)</dt><dd><p>Set the error handler for a communicator</p>
</dd>
<dt id="term-set-name-name">Set_name(name)</dt><dd><p>Set the print name for this communicator</p>
</dd>
<dt id="term-ssend-buf-dest-0-tag-0">Ssend(buf, dest=0, tag=0)</dt><dd><p>Blocking send in synchronous mode</p>
</dd>
<dt id="term-ssend-init-buf-dest-0-tag-0">Ssend_init(buf, dest=0, tag=0)</dt><dd><p>Persistent request for a send in synchronous mode</p>
</dd>
</dl>
</div>
<div class="section" id="lowercase-communication">
<h3>“Lowercase” Communication<a class="headerlink" href="#lowercase-communication" title="Permalink to this headline">¶</a></h3>
<dl class="glossary simple">
<dt id="term-allgather-sendobj-none-recvobj-none">allgather(sendobj=None, recvobj=None)</dt><dd><p>Gather to All</p>
</dd>
<dt id="term-allreduce-sendobj-none-recvobj-none-op-sum">allreduce(sendobj=None, recvobj=None, op=SUM)</dt><dd><p>Reduce to All</p>
</dd>
<dt id="term-alltoall-sendobj-none-recvobj-none">alltoall(sendobj=None, recvobj=None)</dt><dd><p>All to All Scatter/Gather</p>
</dd>
<dt id="term-56">barrier()</dt><dd><p>Barrier</p>
</dd>
<dt id="term-bcast-obj-none-root-0">bcast(obj=None, root=0)</dt><dd><p>Broadcast</p>
</dd>
<dt id="term-bsend-obj-none-dest-0-tag-0">bsend(obj=None, dest=0, tag=0)</dt><dd><p>Send in buffered mode</p>
</dd>
<dt id="term-gather-sendobj-none-recvobj-none-root-0">gather(sendobj=None, recvobj=None, root=0)</dt><dd><p>Gather</p>
</dd>
<dt id="term-ibsend-obj-none-dest-0-tag-0">ibsend(obj=None, dest=0, tag=0)</dt><dd><p>Nonblocking send in buffered mode</p>
</dd>
<dt id="term-isend-obj-none-dest-0-tag-0">isend(obj=None, dest=0, tag=0)</dt><dd><p>Nonblocking send</p>
</dd>
<dt id="term-issend-obj-none-dest-0-tag-0">issend(obj=None, dest=0, tag=0)</dt><dd><p>Nonblocking send in synchronous mode</p>
</dd>
<dt id="term-recv-obj-none-source-0-tag-0-status-status-none">recv(obj=None, source=0, tag=0, Status status=None)</dt><dd><p>Receive</p>
</dd>
<dt id="term-reduce-sendobj-none-recvobj-none-op-sum-root-0">reduce(sendobj=None, recvobj=None, op=SUM, root=0)</dt><dd><p>Reduce</p>
</dd>
<dt id="term-scatter-sendobj-none-recvobj-none-root-0">scatter(sendobj=None, recvobj=None, root=0)</dt><dd><p>Scatter</p>
</dd>
<dt id="term-send-obj-none-dest-0-tag-0">send(obj=None, dest=0, tag=0)</dt><dd><p>Send</p>
</dd>
<dt id="term-sendrecv-sendobj-none-dest-0-sendtag-0-recvobj-none-source-0-recvtag-0-status-status-none">sendrecv(sendobj=None, dest=0, sendtag=0, recvobj=None, source=0, recvtag=0, Status status=None)</dt><dd><p>Send and Receive</p>
</dd>
<dt id="term-ssend-obj-none-dest-0-tag-0">ssend(obj=None, dest=0, tag=0)</dt><dd><p>Send in synchronous mode</p>
</dd>
</dl>
</div>
</div>
<div class="section" id="the-op-class-reduction-operations">
<span id="opclass"></span><h2>The <em>Op</em> Class (Reduction Operations)<a class="headerlink" href="#the-op-class-reduction-operations" title="Permalink to this headline">¶</a></h2>
<p>Within the <em>Op</em> class are values that represent predefine operations to be used with the “reduce” functions. There are also methods that allow the creation of user-defined operations. I present here a table of the predefined operations. Full documentation is found here: <a class="reference external" href="http://mpi4py.scipy.org/docs/apiref/mpi4py.MPI.Op-class.html">http://mpi4py.scipy.org/docs/apiref/mpi4py.MPI.Op-class.html</a></p>
<table class="docutils align-center">
<colgroup>
<col style="width: 36%" />
<col style="width: 64%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Name</p></th>
<th class="head"><p>Meaning</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>MPI.MAX</p></td>
<td><p>maximum</p></td>
</tr>
<tr class="row-odd"><td><p>MPI.MIN</p></td>
<td><p>minimum</p></td>
</tr>
<tr class="row-even"><td><p>MPI.SUM</p></td>
<td><p>sum</p></td>
</tr>
<tr class="row-odd"><td><p>MPI.PROD</p></td>
<td><p>product</p></td>
</tr>
<tr class="row-even"><td><p>MPI.LAND</p></td>
<td><p>logical and</p></td>
</tr>
<tr class="row-odd"><td><p>MPI.BAND</p></td>
<td><p>bit-wise and</p></td>
</tr>
<tr class="row-even"><td><p>MPI.LOR</p></td>
<td><p>logical or</p></td>
</tr>
<tr class="row-odd"><td><p>MPI.BOR</p></td>
<td><p>bit-wise or</p></td>
</tr>
<tr class="row-even"><td><p>MPI.LXOR</p></td>
<td><p>logical xor</p></td>
</tr>
<tr class="row-odd"><td><p>MPI.BXOR</p></td>
<td><p>bit-wise xor</p></td>
</tr>
<tr class="row-even"><td><p>MPI.MAXLOC</p></td>
<td><p>max value and location</p></td>
</tr>
<tr class="row-odd"><td><p>MPI.MINLOC</p></td>
<td><p>min value and location</p></td>
</tr>
</tbody>
</table>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h3><a href="index.html">Table of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Appendix</a><ul>
<li><a class="reference internal" href="#instance-methods-of-comm-class">Instance Methods of <em>Comm</em> Class</a><ul>
<li><a class="reference internal" href="#uppercase-communication">“Uppercase” Communication</a></li>
<li><a class="reference internal" href="#lowercase-communication">“Lowercase” Communication</a></li>
</ul>
</li>
<li><a class="reference internal" href="#the-op-class-reduction-operations">The <em>Op</em> Class (Reduction Operations)</a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="IOandDebugging.html"
                        title="previous chapter">I/O, Debugging, and Performance</a></p>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="_sources/appendix.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="IOandDebugging.html" title="I/O, Debugging, and Performance"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">A Python Introduction to Parallel Programming with MPI 1.0.2 documentation</a> &#187;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2013, Jeremy Bejarano.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 2.0.1.
    </div>
  </body>
</html>